{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real book Reccomendation Gameplan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama # newer version of this import from langchain_community.chat_models import ChatOllama idk if it changes anything though\n",
    "from langchain_core.prompts import ChatPromptTemplate # Prompt templates convert raw user input to better input to the LLM (guide reponse)\n",
    "from langchain_core.output_parsers import StrOutputParser # original model output is a message but this function parses it to a string (easier to work with)\n",
    "from langchain_core.messages import HumanMessage, AIMessage # Used to frame history to LLM and retriever\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from filelock import FileLock, Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM that provides a list of book reccomendations (title only) in the format of a python list\n",
    "\n",
    "model = \"llama3.1\" # mistral, llama2, kdl_copilot_llama3, llama3, llama2:13b\n",
    "llm = Ollama(model=model, format='json') # how to structure LLM output: https://python.langchain.com/v0.2/docs/how_to/structured_output/\n",
    "\n",
    "system = \"\"\"Your are a helpful librarian AI assistant. You provide relevant book recommendations based on the context of the users input. \\\n",
    "Output your response in json, structured with only the book title. \\\n",
    "Include at least 7 relevant  books. \\ \n",
    "\n",
    "Here are some examples of proper json output based on an example prompts:\n",
    "\n",
    "example_user: I like mystery book, what are some recommendations like that if I just read Louise Penny?\n",
    "example_assistant: {{\"book_titles\": [\n",
    "    \"A Rule Against Murder\",\n",
    "    \"The Word is Murder\",\n",
    "    \"Bury Your Dead\"]}}\n",
    "\n",
    "example_user: What books should I read after 1984 by George Orwell??\n",
    "example_assistant: {{\"book_titles\": [\n",
    "    \"Fahrenheit 451\",\n",
    "    \"Animal Farm\",\n",
    "    \"Brave new world\",\n",
    "    \"The Handmaid's Tale\",\n",
    "    \"Lord of the Flies\",\n",
    "    \"A Clockwork Orange\"]}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([  # LLM unreliable for ISBN number but does good for book titles\n",
    "    (\"system\", system),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "orig_prompt = \"I liked the mistborn series by sanderson, what are some books like it?\"\n",
    "\n",
    "output1 = chain.invoke({\"input\": orig_prompt}) \n",
    "\n",
    "print(output1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convering the json output of the LLM into a python list \n",
    "import json\n",
    "\n",
    "# Replace 'your_data' with your actual JSON data\n",
    "data = json.loads(output1)\n",
    "\n",
    "# Extract the list of book titles from the 'book_titles' property\n",
    "book_titles = data['book_titles']\n",
    "\n",
    "# Example output\n",
    "#book_titles = ['The Silent Companions', 'The dangers of mr.bigbe', 'The Word is Murder', 'The 7 1/2 Deaths of Evelyn Hardcastle', 'The Devil in the Marshalsea', 'The Blind Barber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles = ['The Silent Companions', 'The dangers of mr.bigbe', 'The Word is Murder', 'The 7 1/2 Deaths of Evelyn Hardcastle', 'The Devil in the Marshalsea', 'The Blind Barber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a list of book titles in the form of a python list, provide each title to the google reads API in order to get the author of each book (needed to match book title to title in KDL database)\n",
    "# Because ISBN number is not a direct match in our comparison dataset, it's difficult to use this API in our dataset each book title would have to be associated with it's various ISBN versions \n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Initalize dictionary that will store all API output  \n",
    "master_dict = {}\n",
    "\n",
    "# Function that takes list of book titles as input and returns dictionary with book title as keys and author as value\n",
    "def get_author(titles):\n",
    "    for title in titles:\n",
    "        url = f\"https://www.googleapis.com/books/v1/volumes?q={title}&maxResults=1\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json() \n",
    "        author = data[\"items\"][0][\"volumeInfo\"][\"authors\"][0]\n",
    "        last_name = author.split(\" \")[1]\n",
    "        #print(\"Author:\", last_name)\n",
    "        \n",
    "        # Writing the output from the google reads API into a dict then updating it to master\n",
    "        temp_dict = {title: last_name}\n",
    "        master_dict.update(temp_dict)\n",
    "        #isbn_13 = data[\"items\"][0][\"volumeInfo\"][\"industryIdentifiers\"][0][\"identifier\"]\n",
    "        #print(\"ISBN-13:\", isbn_13)\n",
    "\n",
    "        time.sleep(.5) \n",
    "    return master_dict\n",
    "\n",
    "master_dict = get_author(book_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out the dictionary \n",
    "master_dict # values() & keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the KDL database we're going to compare our LLM reccomendation output against \n",
    "monster = pd.read_excel(r'Book db\\kdl_report_edited.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"The Sea of Tranquility\"\n",
    "\n",
    "key_lower = key.lower() # Converts titles from both API and KDL database to lowercase, easier search when finding observational rows \n",
    "monster_title = monster['title'].str.lower()\n",
    "\n",
    "row_indices = monster.loc[monster_title.str.contains(key_lower)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_recs(master_dict):\n",
    "    # Initialize an empty DataFrame for storing index data\n",
    "    book_recs = pd.DataFrame(columns=[\"Title\", \"Author\", \"index\"])  # Initialize with column names\n",
    "\n",
    "    # Use .loc to find and select rows in our KDL database where title and author match the LLM output\n",
    "    for key, value in master_dict.items():\n",
    "        \n",
    "        key_lower = key.lower() # Converts titles from both API and KDL database to lowercase, easier search when finding observational rows \n",
    "        monster_title = monster['title'].str.lower()\n",
    "        \n",
    "        # Find rows where the lowercase column contains the lowercase search string\n",
    "        row_indices = monster.loc[monster_title.str.contains(key_lower)].index.tolist()\n",
    "        if row_indices is not None: # If we a book title matches from the LLM to KDL database then we keep going to find the exact observation   \n",
    "            for index in row_indices: \n",
    "                value_lower = value.lower() # standardize the string casing for both values of authors from our API and KDL databse for easier search \n",
    "                monster_author = monster['Author'].str.lower()\n",
    "                \n",
    "                if value_lower in monster_author[index]:  # Matches the authors last name we got from the API to find the correct observation in KDL database\n",
    "                    new_data = pd.DataFrame({\n",
    "                        \"Title\": [key],\n",
    "                        \"Author\": [value],\n",
    "                        \"index\": [index]\n",
    "                    })\n",
    "                    book_recs = pd.concat([book_recs, new_data], ignore_index=True)\n",
    "        else: # Writes in blank index if title string from LLM is not found in KDL database\n",
    "            new_data = pd.DataFrame({\n",
    "                \"Title\": [key],\n",
    "                \"Author\": [value],\n",
    "                \"index\": [\"\"]\n",
    "            })\n",
    "            book_recs = pd.concat([book_recs, new_data], ignore_index=True)\n",
    "    return book_recs\n",
    "\n",
    "book_recs = match_recs(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the index output of match_recs function ensuring it leads to the book it says in the db\n",
    "list(book_recs[\"index\"])\n",
    "\n",
    "row_data = monster.iloc[50115]\n",
    "print(row_data)\n",
    "author_value = row_data['summary']\n",
    "#print(\"Author:\", author_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops all rows except for the first occurance of every title\n",
    "book_recs.drop_duplicates(subset='Title', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the index variable from book_recs and making it into a list for itterating \n",
    "index_list = book_recs['index']\n",
    "\n",
    "#initalizing empty dictionary to put specific book and summary data from KDL db in  \n",
    "llm_data = {}\n",
    "\n",
    "for index in index_list:\n",
    "    row_data = monster.iloc[index] # Finds the specific row for each index variable saving all info \n",
    "    #print(row_data, \"\\n\")\n",
    "    summary_value = row_data['summary'] # Keep in mind this summary variable from Sheri's dataset is truncated \n",
    "    title_value = row_data['title']\n",
    "    temp_dict = {title_value: summary_value} # updates temp dict into llm_data for each book in our index_list\n",
    "    llm_data.update(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For books that are in KDL's database (AKA have am index present in book_recs df) this LLM recommends them in relation to the original question! \n",
    "\n",
    "model = \"llama3\" # mistral, llama2, kdl_copilot_llama3, llama3, llama2:13b\n",
    "llm = Ollama(model=model, temperature=0)\n",
    "\n",
    "system2 = \"\"\"Your are a helpful librarian AI assistant. You know a lot about books and have great recommendation advice . \\\n",
    "Given a python dictionary of book titles and their associated summary as extra context, you can provide me with a summary of why those books are great recommendations in relation to the original prompt. \\\n",
    "If a book in the python dictionary doesn't at all match the themes of the other books in the original prompt or python dictionary ignore that specific book in your output,\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system2), \n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser # If our kdl db had a link to bibliocommons that would be sweet to add in here for easy staff access! \n",
    "\n",
    "output2 = chain.invoke({\"input\": f\"Given the follow python dictionary of book titles and associated summaries: {llm_data}, provide a summary of why those books are great reccomendations in relation to the original prompt: {orig_prompt}.\"}) \n",
    "\n",
    "print(output2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output into json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"prompt\": orig_prompt, \"output\": output2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the Address DB, appending the current address results, and then resaves it \n",
    "save_folder = r\"C:\\Users\\Ryan\\Coding Projects\\KDL Project\\AI PT\\LLM book rec\\outputs\"\n",
    "file_path = os.path.join(save_folder, 'LLM_Recs_db.json')\n",
    "lock_file_path = file_path + '.lock'\n",
    "\n",
    "# Ensure the save folder exists\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Function to save the updated address database\n",
    "def resave_json(dict):\n",
    "    lock = FileLock(lock_file_path, timeout=10) \n",
    "\n",
    "    try:\n",
    "        with lock:\n",
    "            # Load the address database within the lock context\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r') as f:\n",
    "                    rec_db = json.load(f)\n",
    "            else:\n",
    "                rec_db = []\n",
    "\n",
    "            # Append the new entry\n",
    "            rec_db.append(dict)\n",
    "\n",
    "            # Save the updated address database\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(rec_db, f, indent=4)\n",
    "\n",
    "            print(f\"Results have been saved to '{file_path}'\")\n",
    "\n",
    "    except Timeout:\n",
    "        print(\"Another process is currently accessing the file. Please try again later.\")\n",
    "\n",
    "resave_json(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function testing from functions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_book_rec import *\n",
    "\n",
    "orig_prompt = \"Recommend some quintessential science fiction books\"\n",
    "\n",
    "output1 = input_llm(orig_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles = convert_json(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = get_author(book_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_recs = match_recs(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_recs = match_recs(master_dict)\n",
    "\n",
    "# Drops all rows except for the first occurance of every title\n",
    "book_recs.drop_duplicates(subset='Title', keep='first', inplace=True)\n",
    "\n",
    "# taking the index variable from book_recs and making it into a list for itterating \n",
    "index_list = book_recs['index']\n",
    "\n",
    "#initalizing empty dictionary to put specific book and summary data from KDL db in  \n",
    "llm_data = {}\n",
    "\n",
    "for index in index_list:\n",
    "    row_data = monster.iloc[index] # Finds the specific row for each index variable saving all info \n",
    "    #print(row_data, \"\\n\")\n",
    "    summary_value = row_data['summary'] # Keep in mind this summary variable from Sheri's dataset is truncated \n",
    "    title_value = row_data['title']\n",
    "    temp_dict = {title_value: summary_value} # updates temp dict into llm_data for each book in our index_list\n",
    "    llm_data.update(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = output_llm(llm_data, orig_prompt)\n",
    "print(output2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
